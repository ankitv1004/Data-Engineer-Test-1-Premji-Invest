{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'capabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m driver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/chromedriver\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize Selenium WebDriver\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Open the webpage\u001b[39;00m\n\u001b[0;32m     11\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://yourstory.com/search?q=HDFC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:50\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[0;32m     49\u001b[0m finder \u001b[38;5;241m=\u001b[39m DriverFinder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice, options)\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfinder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_browser_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     51\u001b[0m     options\u001b[38;5;241m.\u001b[39mbinary_location \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mget_browser_path()\n\u001b[0;32m     52\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:47\u001b[0m, in \u001b[0;36mDriverFinder.get_browser_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_browser_path\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowser_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:56\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths\n\u001b[1;32m---> 56\u001b[0m browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapabilities\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service\u001b[38;5;241m.\u001b[39mpath\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Path to your web driver (e.g., ChromeDriver)\n",
    "driver_path = '/path/to/chromedriver'\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "# Open the webpage\n",
    "url = \"https://yourstory.com/search?q=HDFC\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load completely\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# Extract the page's source code after JavaScript execution\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Example: Extract divs with specific class\n",
    "div_content = soup.find_all('div', class_='your-class-name')\n",
    "for div in div_content:\n",
    "    print(div.text)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to fetch and parse the data\n",
    "def fetch_data(url):\n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for request errors\n",
    "       #     print(response)\n",
    "\n",
    "        # Parse the HTML content\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        print(soup)\n",
    "        \n",
    "        # Example: Get the title of the page\n",
    "        title = soup.title.string if soup.title else \"No Title Found\"\n",
    "        print(title)\n",
    "        \n",
    "        # Example: Get the first paragraph or some other content\n",
    "        paragraph = soup.find('p').get_text() if soup.find('p') else \"No Paragraph Found\"\n",
    "        \n",
    "        return {\"url\": url, \"title\": title, \"paragraph\": paragraph}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"url\": url, \"error\": str(e)}\n",
    "\n",
    "# URLs to scrape\n",
    "urls = [  \"https://yourstory.com/search?q=HDFC\", \"https://backend.finshots.in/backend/search/?q=HDFC\"]\n",
    "\n",
    "# Fetch data from both URLs\n",
    "for url in urls:\n",
    "    data = fetch_data(url)\n",
    "    print(f\"Data from {data['url']}:\")\n",
    "    print(f\"Title: {data['title']}\")\n",
    "    print(f\"First Paragraph: {data['paragraph']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to fetch and parse the data\n",
    "\n",
    "def fetch_data():\n",
    "    df=pd.DataFrame(columns=['title','post_url','published_date','article'])\n",
    "    # URLs to scrape\n",
    "    keywords=[\"HDFC\",\"Tata Motars\"]\n",
    "    # Fetch data from both URLs\n",
    "    data=[]\n",
    "\n",
    "    for keyword in keywords:\n",
    "        url = f\"https://backend.finshots.in/backend/search/?q={keyword}\"\n",
    "        try:\n",
    "            # Fetch the webpage content\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Check for request errors\n",
    "            #print(response.text)\n",
    "\n",
    "            # Parse the HTML content\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            soup=json.loads(response.content)\n",
    "            matches=soup[\"matches\"]\n",
    "            #print(matches[0])\n",
    "\n",
    "            for match in matches:\n",
    "                # Example: Get the title of the page\n",
    "                title = match['title']\n",
    "                #print(title)\n",
    "                \n",
    "                # url = match['post_url']\n",
    "                post_url=match['post_url']\n",
    "                published_date=match['published_date']\n",
    "                req = requests.get(url=post_url)\n",
    "                soup = BeautifulSoup(req.content, 'lxml')\n",
    "                # Example: Get the first paragraph or some other content\n",
    "                paragraph = soup.find('div',{\"class\":\"post-content\"}).text.strip()#.get_text() \n",
    "                #paragraph=soup.text.strip()\n",
    "                row=pd.DataFrame({ \"title\": [title],\"post_url\": [post_url],'published_date':[published_date], \"article\": [paragraph]})\n",
    "                #print(row)\n",
    "                df=df._append(row,ignore_index=True)\n",
    "            data.append(df)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {\"url\": url, \"error\": str(e)}\n",
    "\n",
    "    return data\n",
    "\n",
    "data=fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HDFC is in trouble — Has the elephant forgotte...</td>\n",
       "      <td>https://finshots.in/markets/hdfc-is-in-trouble/</td>\n",
       "      <td>2024-01-19T18:38:03.109000+00:00</td>\n",
       "      <td>In today's Finshots, we explain why HDFC Bank'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45 years later, HDFC bids goodbye to Dalal Street</td>\n",
       "      <td>https://finshots.in/archive/45-years-later-hdf...</td>\n",
       "      <td>2023-07-14T01:30:00+00:00</td>\n",
       "      <td>On 12th July at 3:30 pm, the stock ticker HDFC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDFC bids farewell to its ₹10,000 crore educat...</td>\n",
       "      <td>https://finshots.in/archive/hdfc-bids-farewell...</td>\n",
       "      <td>2023-06-22T01:30:00+00:00</td>\n",
       "      <td>In today’s Finshots, we explain why internatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 investing lessons from HDFC’s Prashant Jain</td>\n",
       "      <td>https://finshots.in/markets/investing-lessons-...</td>\n",
       "      <td>2022-09-09T10:46:32+00:00</td>\n",
       "      <td>In today's Finshots we describe a few lessons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weekly Wrapup - Understanding the HDFC Merger</td>\n",
       "      <td>https://finshots.in/archive/weekly-wrapup-unde...</td>\n",
       "      <td>2022-04-08T16:51:54.934000+00:00</td>\n",
       "      <td>Before we get to today's story, a quick recap ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "6  HDFC is in trouble — Has the elephant forgotte...   \n",
       "8  45 years later, HDFC bids goodbye to Dalal Street   \n",
       "5  HDFC bids farewell to its ₹10,000 crore educat...   \n",
       "7      3 investing lessons from HDFC’s Prashant Jain   \n",
       "3      Weekly Wrapup - Understanding the HDFC Merger   \n",
       "\n",
       "                                            post_url  \\\n",
       "6    https://finshots.in/markets/hdfc-is-in-trouble/   \n",
       "8  https://finshots.in/archive/45-years-later-hdf...   \n",
       "5  https://finshots.in/archive/hdfc-bids-farewell...   \n",
       "7  https://finshots.in/markets/investing-lessons-...   \n",
       "3  https://finshots.in/archive/weekly-wrapup-unde...   \n",
       "\n",
       "                     published_date  \\\n",
       "6  2024-01-19T18:38:03.109000+00:00   \n",
       "8         2023-07-14T01:30:00+00:00   \n",
       "5         2023-06-22T01:30:00+00:00   \n",
       "7         2022-09-09T10:46:32+00:00   \n",
       "3  2022-04-08T16:51:54.934000+00:00   \n",
       "\n",
       "                                             article  \n",
       "6  In today's Finshots, we explain why HDFC Bank'...  \n",
       "8  On 12th July at 3:30 pm, the stock ticker HDFC...  \n",
       "5  In today’s Finshots, we explain why internatio...  \n",
       "7  In today's Finshots we describe a few lessons ...  \n",
       "3  Before we get to today's story, a quick recap ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(data):\n",
    "    for i in range(0,len(data)):\n",
    "        # Sorting by column \"published_date\"\n",
    "        data[i]=data[i].sort_values(by=['published_date'], ascending=False)\n",
    "        data[i]=data[i].iloc[0:5,:]\n",
    "        #print(data[i])\n",
    "    return data\n",
    "\n",
    "clean_data(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>article</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HDFC is in trouble — Has the elephant forgotte...</td>\n",
       "      <td>https://finshots.in/markets/hdfc-is-in-trouble/</td>\n",
       "      <td>2024-01-19T18:38:03.109000+00:00</td>\n",
       "      <td>In today's Finshots, we explain why HDFC Bank'...</td>\n",
       "      <td>0.159779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45 years later, HDFC bids goodbye to Dalal Street</td>\n",
       "      <td>https://finshots.in/archive/45-years-later-hdf...</td>\n",
       "      <td>2023-07-14T01:30:00+00:00</td>\n",
       "      <td>On 12th July at 3:30 pm, the stock ticker HDFC...</td>\n",
       "      <td>0.632368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDFC bids farewell to its ₹10,000 crore educat...</td>\n",
       "      <td>https://finshots.in/archive/hdfc-bids-farewell...</td>\n",
       "      <td>2023-06-22T01:30:00+00:00</td>\n",
       "      <td>In today’s Finshots, we explain why internatio...</td>\n",
       "      <td>0.426931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 investing lessons from HDFC’s Prashant Jain</td>\n",
       "      <td>https://finshots.in/markets/investing-lessons-...</td>\n",
       "      <td>2022-09-09T10:46:32+00:00</td>\n",
       "      <td>In today's Finshots we describe a few lessons ...</td>\n",
       "      <td>0.757981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weekly Wrapup - Understanding the HDFC Merger</td>\n",
       "      <td>https://finshots.in/archive/weekly-wrapup-unde...</td>\n",
       "      <td>2022-04-08T16:51:54.934000+00:00</td>\n",
       "      <td>Before we get to today's story, a quick recap ...</td>\n",
       "      <td>0.832144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "6  HDFC is in trouble — Has the elephant forgotte...   \n",
       "8  45 years later, HDFC bids goodbye to Dalal Street   \n",
       "5  HDFC bids farewell to its ₹10,000 crore educat...   \n",
       "7      3 investing lessons from HDFC’s Prashant Jain   \n",
       "3      Weekly Wrapup - Understanding the HDFC Merger   \n",
       "\n",
       "                                            post_url  \\\n",
       "6    https://finshots.in/markets/hdfc-is-in-trouble/   \n",
       "8  https://finshots.in/archive/45-years-later-hdf...   \n",
       "5  https://finshots.in/archive/hdfc-bids-farewell...   \n",
       "7  https://finshots.in/markets/investing-lessons-...   \n",
       "3  https://finshots.in/archive/weekly-wrapup-unde...   \n",
       "\n",
       "                     published_date  \\\n",
       "6  2024-01-19T18:38:03.109000+00:00   \n",
       "8         2023-07-14T01:30:00+00:00   \n",
       "5         2023-06-22T01:30:00+00:00   \n",
       "7         2022-09-09T10:46:32+00:00   \n",
       "3  2022-04-08T16:51:54.934000+00:00   \n",
       "\n",
       "                                             article  sentiment_score  \n",
       "6  In today's Finshots, we explain why HDFC Bank'...         0.159779  \n",
       "8  On 12th July at 3:30 pm, the stock ticker HDFC...         0.632368  \n",
       "5  In today’s Finshots, we explain why internatio...         0.426931  \n",
       "7  In today's Finshots we describe a few lessons ...         0.757981  \n",
       "3  Before we get to today's story, a quick recap ...         0.832144  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sentiment_score(data):\n",
    "    import random\n",
    "    def mock_sentiment_api(text):\n",
    "        sentiment_score = random.uniform(0, 1)\n",
    "        return sentiment_score \n",
    "\n",
    "    for i in range(0,len(data)):\n",
    "        data[i]['sentiment_score'] = data[i].apply(mock_sentiment_api, axis=1)\n",
    "    return data\n",
    "generate_sentiment_score(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "keys=[\"dd\",\"ee\"]\n",
    "b={\"ddd\":1,'dee':2}\n",
    "for i in range(0,len(keys)):\n",
    "    a=b[f\"d{keys[i]}\"]\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import hashlib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_articles():\n",
    "    # Code to scrape articles from finshots.in for keywords HDFC and Tata Motors\n",
    "    query = [\"HDFC\",\"Tata Motors\"]\n",
    "\n",
    "    article_df_final = pd.DataFrame(columns=['aid','source','type','title','url','publishDate','text','query'])\n",
    "    for each_query in query:\n",
    "        article_df = pd.DataFrame(columns=['aid','source','type','title','url','publishDate','text'])\n",
    "        r = requests.get(url=\"https://backend.finshots.in/backend/search/?q=\"+each_query)\n",
    "        out = json.loads(r.content)\n",
    "        print(out)\n",
    "        matches = out['matches']\n",
    "        for match in matches:\n",
    "            title = match['title']\n",
    "            publishDate = datetime.datetime.strptime(match['published_date'].split('T')[0],\"%Y-%m-%d\").date().strftime('%Y-%m-%d')\n",
    "            url = match['post_url']\n",
    "            req = requests.get(url=url)\n",
    "            #print(req.text)\n",
    "            soup = BeautifulSoup(req.content, 'lxml')\n",
    "            p_tags = soup.find_all('div',{\"class\":\"post-content\"})\n",
    "            text = \"\"\n",
    "            hash_obj = hashlib.sha256(url.encode('utf-8'))\n",
    "            hex_hash = hash_obj.hexdigest()\n",
    "            aid = str(hex_hash)\n",
    "            for p in p_tags:\n",
    "                text+=p.text\n",
    "            article_df = pd.concat([article_df, pd.DataFrame([[aid,'FinShots','Article',title,url,publishDate,text,each_query]],columns=['aid','source','type','title','url','publishDate','text','query'])],ignore_index=True)\n",
    "        # Taking first five records\n",
    "        article_df.sort_values(by='publishDate', ascending=False, inplace=True)\n",
    "        first_five_records = article_df.head(5)\n",
    "        article_df_final = pd.concat([article_df_final,first_five_records],ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return article_df_final\n",
    "\n",
    "fetch_articles().head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
